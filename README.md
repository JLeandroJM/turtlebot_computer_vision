# ğŸ¤– TurtleBot4 Intelligent Pursuit System

Sistema autÃ³nomo de persecuciÃ³n visual con navegaciÃ³n inteligente para TurtleBot4 Lite. El robot persigue un objetivo mÃ³vil (perro robot) esquivando obstÃ¡culos dinÃ¡micos mediante fusiÃ³n de sensores (cÃ¡mara + LiDAR).

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-00FFFF.svg)](https://github.com/ultralytics/ultralytics)
[![ROS2](https://img.shields.io/badge/ROS2-Humble-blue.svg)](https://docs.ros.org/en/humble/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Entrenamiento del Modelo](#-entrenamiento-del-modelo)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Resultados](#-resultados)
- [Troubleshooting](#-troubleshooting)
- [Contribuciones](#-contribuciones)
- [Licencia](#-licencia)

---

## ğŸŒŸ CaracterÃ­sticas

### DetecciÃ³n Visual
- âœ… **YOLOv11s** entrenado custom (mAP50: 83.78%, Precision: 98.34%, Recall: 100%)
- âœ… Inferencia en tiempo real (~15 FPS)
- âœ… DetecciÃ³n robusta con alta confianza

### NavegaciÃ³n Inteligente
- ğŸ§­ **Memoria espacial**: Estima distancia y Ã¡ngulo del objetivo
- ğŸ”„ **Wall-following**: Rodea obstÃ¡culos persistentemente
- ğŸ¯ **5 estados**: TRACKING â†’ EVADING â†’ NAVIGATING â†’ SEARCHING â†’ LOST
- ğŸ“¡ **FusiÃ³n de sensores**: CÃ¡mara + LiDAR para decisiones robustas

### Arquitectura AsÃ­ncrona
- âš¡ **Latencia ultra-baja**: 50-100ms (30x mejora vs secuencial)
- ğŸ”€ **6 tareas paralelas**: RX CÃ¡mara, RX LiDAR, YOLO, Control, 2x VisualizaciÃ³n
- ğŸš€ **30 Hz de comandos**: Control fluido sin lag
- ğŸ“Š **VisualizaciÃ³n dual**: Ventana de cÃ¡mara + ventana de LiDAR

### Robustez
- ğŸ›¡ï¸ **RecuperaciÃ³n inteligente**: Encuentra objetivo tras oclusiones (2-4s)
- ğŸš§ **EvasiÃ³n activa**: No se detiene, esquiva mientras mantiene vista
- ğŸŒ **BÃºsqueda dirigida**: Usa Ãºltima posiciÃ³n conocida para navegar

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TURTLEBOT4 ROBOT                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ROS2 Nodes:                                                â”‚
â”‚  â”œâ”€ enviador.py         â†’ UDP 6000 (ImÃ¡genes JPEG)         â”‚
â”‚  â””â”€ enviador_lidar.py   â†’ UDP 6001 (Scans LiDAR)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ WiFi / Ethernet
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PC CONTROL (autonomo_async.py)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tareas AsÃ­ncronas:                                         â”‚
â”‚                                                              â”‚
â”‚  1. RX CÃ¡mara (30 FPS)    â”                                 â”‚
â”‚     â””â†’ Queue(2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â†’ 2. YOLO (15 FPS)              â”‚
â”‚                           â”‚     â””â†’ Queue(3) â”€â”€â”€â”€â”€â”          â”‚
â”‚  3. RX LiDAR (10 FPS)    â”€â”¤                      â”‚          â”‚
â”‚     â””â†’ Global var         â”‚                      â†“          â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ 4. Control (30 Hz)   â”‚
â”‚                                          â”œâ†’ NavegaciÃ³n      â”‚
â”‚                                          â””â†’ UDP 5007 (Twist)â”‚
â”‚                                                              â”‚
â”‚  5. VisualizaciÃ³n CÃ¡mara  â†â”€â”€ Global state                  â”‚
â”‚  6. VisualizaciÃ³n LiDAR   â†â”€â”€ Global LiDAR data            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline de Procesamiento

```
Imagen â†’ DecodificaciÃ³n â†’ YOLO â†’ BBox â†’ Control â†’ Velocidades
  â†“                                 â†“        â†“
LiDAR â†’ Sectores â†’ ObstÃ¡culos â†’ Memoria â†’ NavegaciÃ³n
```

---

## ğŸ“¦ Requisitos

### Hardware
- **Robot**: TurtleBot4 Lite (Create3 + Raspberry Pi 4 + RPLIDAR A1)
- **PC**: Laptop/Desktop con WiFi (macOS/Linux/Windows)
- **ConexiÃ³n**: Misma red WiFi que el robot

### Software

#### En el Robot (TurtleBot4)
- Ubuntu 22.04
- ROS2 Humble
- Python 3.10+

#### En el PC
- Python 3.8+
- OpenCV 4.x
- NumPy
- Ultralytics (YOLOv11)
- asyncio (built-in)

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/turtlebot4-pursuit.git
cd turtlebot4-pursuit
```

### 2. Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install --upgrade pip
pip install opencv-python numpy ultralytics torch
```

### 4. Verificar instalaciÃ³n

```bash
python3 -c "import cv2, numpy, ultralytics; print('âœ… InstalaciÃ³n correcta')"
```

### 5. Configurar robot

Copiar scripts al robot:

```bash
# Desde tu PC
scp turtle/enviador.py ubuntu@<ROBOT_IP>:~/
scp turtle/enviador_lidar.py ubuntu@<ROBOT_IP>:~/
```

---

## ğŸ® Uso

### Paso 1: Iniciar transmisores en el robot

```bash
# SSH al robot
ssh ubuntu@<ROBOT_IP>

# Terminal 1: Enviar imÃ¡genes
python3 enviador.py

# Terminal 2: Enviar LiDAR
python3 enviador_lidar.py
```

### Paso 2: Ejecutar sistema de control en PC

```bash
# En tu PC
python3 autonomo_async.py
```

### Paso 3: Observar el comportamiento

**Ventana 1 - CÃ¡mara**:
- Bounding boxes verdes en objetivo detectado
- Panel superior con mÃ©tricas (FPS, latencia, estado)
- Modo de operaciÃ³n en tiempo real

**Ventana 2 - LiDAR**:
- Vista polar del entorno
- Puntos rojos = obstÃ¡culos cerca
- Puntos verdes = espacio libre
- X amarilla = objetivo estimado (cuando no visible)

**Consola**:
```
[CTRL] ğŸ¯ SIGUIENDO âš¡ PERSIGUIENDO | v=0.45 m/s, w=-0.15 rad/s
[CTRL] ğŸ§­ HACIA OBJETIVO 30Â° (1.8m) | v=0.30 m/s, w=-0.35 rad/s
[CTRL] ğŸ”„ RODEANDO â¬…ï¸ IZQUIERDA (obj 0.45m) | v=0.13 m/s, w=0.42 rad/s
```

### Controles

- **Q**: Cerrar visualizaciÃ³n y detener robot
- **Ctrl+C**: Salida de emergencia

---

## ğŸ“ Entrenamiento del Modelo

### Dataset

1. **Captura**: Grabar video desde cÃ¡mara del TurtleBot4
   ```bash
   # En el robot
   ros2 run image_view video_recorder image:=/oakd/rgb/preview/image_raw
   ```

2. **Procesamiento**: Extraer frames
   ```bash
   ffmpeg -i video.mp4 -vf fps=10 frames/frame_%04d.jpg
   ```

3. **Etiquetado**: Usar [Roboflow](https://roboflow.com)
   - Crear proyecto tipo "Object Detection"
   - Subir frames (~500 imÃ¡genes)
   - Anotar bounding boxes manualmente
   - Aplicar augmentation (flip, rotate, brightness)
   - Exportar en formato YOLOv11

### Entrenamiento

Usar el notebook proporcionado:

```bash
# En Google Colab con GPU
jupyter notebook train_yolo_colab.ipynb
```

O entrenar localmente:

```python
from ultralytics import YOLO

# Cargar modelo pre-entrenado
model = YOLO('yolo11s.pt')

# Entrenar
results = model.train(
    data='data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    name='turtlebot_pursuit'
)

# Guardar mejor modelo
model.save('models_trained/best11s.pt')
```

### ValidaciÃ³n

```bash
# Evaluar modelo
yolo val model=models_trained/best11s.pt data=data.yaml

# Inferencia en imagen de prueba
yolo predict model=models_trained/best11s.pt source=test/images/
```

---

## ğŸ“ Estructura del Proyecto

```
turtlebot4-pursuit/
â”œâ”€â”€ autonomo_async.py          # ğŸ¯ Sistema principal de control
â”œâ”€â”€ receptor_lidar.py           # ğŸ“¡ Receptor standalone LiDAR (testing)
â”œâ”€â”€ compare_performance.py      # ğŸ“Š Benchmark latencia
â”‚
â”œâ”€â”€ turtle/                     # ğŸ¤– Scripts del robot
â”‚   â”œâ”€â”€ enviador.py            # Transmisor de imÃ¡genes
â”‚   â””â”€â”€ enviador_lidar.py      # Transmisor de LiDAR
â”‚
â”œâ”€â”€ models_trained/             # ğŸ§  Modelos entrenados
â”‚   â”œâ”€â”€ best11s.pt             # Modelo YOLOv11s final
â”‚   â””â”€â”€ training_results/      # Curvas de entrenamiento
â”‚
â”œâ”€â”€ other_models/               # ğŸ“¦ Modelos auxiliares
â”‚   â”œâ”€â”€ best11s.pt             # Backup del modelo
â”‚   â””â”€â”€ yolo11n.pt             # Modelo nano (mÃ¡s rÃ¡pido)
â”‚
â”œâ”€â”€ data.yaml                   # âš™ï¸ ConfiguraciÃ³n del dataset
â”‚
â”œâ”€â”€ train/                      # ğŸ“š Dataset entrenamiento (gitignore)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”‚
â”œâ”€â”€ valid/                      # âœ… Dataset validaciÃ³n (gitignore)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”‚
â”œâ”€â”€ test/                       # ğŸ§ª Dataset prueba (gitignore)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”‚
â”œâ”€â”€ backups/                    # ğŸ’¾ Versiones anteriores
â”œâ”€â”€ web/                        # ğŸŒ Experimentos web (deprecated)
â”‚
â”œâ”€â”€ NAVEGACION_INTELIGENTE.md  # ğŸ“– DocumentaciÃ³n navegaciÃ³n
â”œâ”€â”€ README.md                   # ğŸ“„ Este archivo
â”œâ”€â”€ .gitignore                  # ğŸš« Archivos excluidos
â””â”€â”€ requirements.txt            # ğŸ“‹ Dependencias Python
```

---

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros del Robot

En `autonomo_async.py`:

```python
# DirecciÃ³n IP del robot
ROBOT_IP = "10.182.184.101"  # Cambiar segÃºn tu robot

# Puertos de comunicaciÃ³n
IMG_PORT = 6000   # ImÃ¡genes
LIDAR_PORT = 6001 # LiDAR
CTRL_PORT = 5007  # Comandos

# ParÃ¡metros de control
MAX_LIN = 0.5     # Velocidad lineal mÃ¡xima (m/s)
MAX_ANG = 0.7     # Velocidad angular mÃ¡xima (rad/s)

# Umbrales de detecciÃ³n
CONFIDENCE_THRESHOLD = 0.25  # Confianza mÃ­nima YOLO
OBSTACLE_DISTANCE = 0.5      # Distancia de seguridad (m)
```

### ParÃ¡metros de NavegaciÃ³n

```python
# Tiempo de memoria espacial
MEMORY_TIMEOUT = 3.0  # segundos

# Velocidades de navegaciÃ³n
NAV_SPEED = 0.6        # 60% en navegaciÃ³n normal
WALL_FOLLOW_SPEED = 0.25  # 25% rodeando obstÃ¡culos

# Frecuencias de procesamiento
YOLO_RATE = 15    # FPS de inferencia
COMMAND_RATE = 30 # Hz de comandos
```

---

## ğŸ“Š Resultados

### MÃ©tricas del Modelo

| MÃ©trica | Valor |
|---------|-------|
| mAP50 | 83.78% |
| Precision | 98.34% |
| Recall | 100% |
| Clases | 1 (perro robot) |
| FPS Inferencia | ~15 FPS |

### Rendimiento del Sistema

| Aspecto | Antes (Secuencial) | Ahora (AsÃ­ncrono) | Mejora |
|---------|-------------------|-------------------|--------|
| Latencia total | ~3000 ms | 50-100 ms | **30x** |
| Tasa de comandos | Variable | 30 Hz constante | âœ… |
| RecuperaciÃ³n tras pÃ©rdida | 8+ seg | 2-4 seg | **3x** |
| Ã‰xito en recuperaciÃ³n | ~50% | ~90% | **+40%** |

### Comportamientos Validados

- âœ… PersecuciÃ³n fluida en lÃ­nea recta
- âœ… Giro suave para centrar objetivo
- âœ… EvasiÃ³n de obstÃ¡culos frontales
- âœ… Rodeo de cajas manteniendo vista
- âœ… NavegaciÃ³n hacia Ãºltima posiciÃ³n tras oclusiÃ³n
- âœ… RecuperaciÃ³n automÃ¡tica del objetivo
- âœ… Manejo de mÃºltiples obstÃ¡culos

---

## ğŸ› Troubleshooting

### Problema: Robot no se conecta

**SÃ­ntomas**: "Timeout" en handshake

**Soluciones**:
1. Verificar IP del robot: `ping <ROBOT_IP>`
2. Verificar misma red WiFi
3. Revisar firewall (permitir puertos 6000, 6001, 5007)
4. Reiniciar scripts del robot

### Problema: Latencia alta

**SÃ­ntomas**: FPS bajos, comandos lentos

**Soluciones**:
1. Cerrar otros programas pesados
2. Reducir `YOLO_RATE` (lÃ­nea 157)
3. Usar modelo mÃ¡s ligero: `yolo11n.pt`
4. Verificar ancho de banda WiFi

### Problema: No detecta al objetivo

**SÃ­ntomas**: Bounding boxes no aparecen

**Soluciones**:
1. Verificar iluminaciÃ³n del entorno
2. Reducir `CONFIDENCE_THRESHOLD` (lÃ­nea 163)
3. Acercarse mÃ¡s al objetivo
4. Re-entrenar con mÃ¡s imÃ¡genes

### Problema: Robot choca con obstÃ¡culos

**SÃ­ntomas**: No esquiva correctamente

**Soluciones**:
1. Aumentar `OBSTACLE_DISTANCE` a 0.7m (lÃ­nea 166)
2. Verificar LiDAR funcionando: ventana "LiDAR Scan"
3. Reducir velocidades de navegaciÃ³n
4. Calibrar Ã¡ngulos de sectores

### Problema: Pierde objetivo frecuentemente

**SÃ­ntomas**: Pasa a LOST rÃ¡pidamente

**Soluciones**:
1. Aumentar tiempo de memoria a 5s (lÃ­nea ~166 en `update_state()`)
2. Mejorar iluminaciÃ³n
3. Re-entrenar con mÃ¡s variedad de Ã¡ngulos
4. Reducir velocidad de persecuciÃ³n

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Ideas para contribuir

- ğŸ¯ DetecciÃ³n multi-objetivo
- ğŸ—ºï¸ SLAM para mapeo del entorno
- ğŸ§  PlanificaciÃ³n global de rutas
- ğŸ“± App mÃ³vil para control remoto
- ğŸ¥ GrabaciÃ³n automÃ¡tica de datasets
- ğŸš€ OptimizaciÃ³n con TensorRT

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

- **Tu Nombre** - *Desarrollo inicial* - [tu-usuario](https://github.com/tu-usuario)

---

## ğŸ™ Agradecimientos

- [Ultralytics](https://github.com/ultralytics/ultralytics) por YOLOv11
- [TurtleBot4](https://turtlebot.github.io/turtlebot4-user-manual/) por la documentaciÃ³n
- [ROS2 Community](https://docs.ros.org/) por las herramientas
- [Roboflow](https://roboflow.com) por la plataforma de etiquetado

---

## ğŸ“š Referencias

- [YOLO: Real-Time Object Detection](https://docs.ultralytics.com/)
- [ROS2 Navigation Stack](https://navigation.ros.org/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [Python asyncio](https://docs.python.org/3/library/asyncio.html)

---

## ğŸ“§ Contacto

Para preguntas o colaboraciones:
- Email: tu-email@ejemplo.com
- GitHub Issues: [Crear issue](https://github.com/tu-usuario/turtlebot4-pursuit/issues)

---

<div align="center">
  
**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub â­**

Hecho con â¤ï¸ y ğŸ¤–

</div>
